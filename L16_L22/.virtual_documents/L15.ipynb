import torch
from torch import nn

# 继承nn.Module这个父类
class Cwq(nn.Module):
    def __init__(self):
        super().__init__()
        
    def forward(self, input):
        output = input + 1
        return output
    

cwq = Cwq()
x = torch.tensor(1.0)
output = cwq(x)
print(output)


import torch 
import torch.nn.functional as F

# 假设input图片为5x5
input = torch.tensor([[1, 2, 0, 3, 1],
                                            [0, 1, 2, 3, 1],
                                            [1, 2, 1, 0, 0],
                                            [5, 2, 3, 1, 1],
                                            [2, 1, 0, 1, 1]])

# 假设卷积核为3x3
kernel = torch.tensor([[1, 2, 1],
                                             [0, 1,  0],
                                             [2, 1,  0]])

print(input.shape)
print(kernel.shape)


input = torch.reshape(input, (1, 1, 5, 5))
kernel = torch.reshape(kernel, (1, 1, 3, 3))


output1 = F.conv2d(input, kernel, stride=1)
print(output1)
output2 = F.conv2d(input, kernel, stride=2)
print(output2)


output3 = F.conv2d(input, kernel, stride=1, padding=1)
print(output3)


import torch 
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter

# 导入CIFAR10数据集并将内部的图片都转化成Tensor
dataset = torchvision.datasets.CIFAR10("../L14/dataset/", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# 利用dataloader导入数据
dataloader = DataLoader(dataset, batch_size=64)


class Cwq(nn.Module):
    def __init__(self):
        super(Cwq, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)

    def forward(self, x):
        x = self.conv1(x)
        return x

cwq = Cwq()
print(cwq)


writer = SummaryWriter("./logs")

step = 0
for data in dataloader:
    imgs, targets = data                           #  用变量接收imgs和targets
    output = cwq(imgs)                           #  送入自定义的网络中
    print(imgs.shape)                              
    print(output.shape)
    output = torch.reshape(output, (-1, 3, 30, 30))         #  (-1, 3, 30, 30）===》 A single dimension may be -1, in which case it’s inferred from the remaining dimensions and the number of elements in input. 
    print(output.shape)
    writer.add_images("Input", imgs, step)
    writer.add_images("output", output, step)
    step += 1


writer.close()


import torch
from torch import nn
from torch.nn import MaxPool2d

# 假设input图片为5x5
input = torch.tensor([[1, 2, 0, 3, 1],
                                            [0, 1, 2, 3, 1],
                                            [1, 2, 1, 0, 0],
                                            [5, 2, 3, 1, 1],
                                            [2, 1, 0, 1, 1]], dtype=torch.float32)                   # 转化成tensor浮点数

input = torch.reshape(input, (-1, 1, 5, 5))
print(input.shape)


class CWQ(nn.Module):
    def __init__(self):
        super(CWQ, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output

cwq2 = CWQ()
output = cwq2(input)
print(output)


class CWQ(nn.Module):
    def __init__(self):
        super(CWQ, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output

cwq2 = CWQ()
output = cwq2(input)
print(output)


import torch 
import torchvision
from torch import nn
from torch.nn import MaxPool2d
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("../L14/dataset", train=False, download=True, transform=torchvision.transforms.transforms.ToTensor())

dataloader = DataLoader(dataset, batch_size=64)

input = torch.tensor([[1, 2, 0, 3, 1],
                                            [0, 1, 2, 3, 1],
                                            [1, 2, 1, 0, 0],
                                            [5, 2, 3, 1, 1],
                                            [2, 1, 0, 1, 1]], dtype=torch.float32)                   # 转化成tensor浮点数



class CWQ(nn.Module):
    def __init__(self):
        super(CWQ, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output

# 创建自定义类的实例
cwq2 = CWQ()

#
writer = SummaryWriter("./logs_maxpool")

stp = 0
for data in dataloader:
    imgs, targets = data
    writer.add_images("Input", imgs, stp)
    output = cwq2(imgs)
    writer.add_images("output", output, stp)
    stp += 1
    
writer.close()


import torch
from torch.nn import ReLU


input = torch.tensor([[1, -0.5],
                                            [-1, 3]])

input = torch.reshape(input, (-1, 1, 2, 2))
print(input.shape)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.relu1 = ReLU()
        
    def forward(self, input):
        output = self.relu1(input)
        return output

tudui = Tudui()
output = tudui(input)
print(output)


import torch 
from torch import nn
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import dataloader

# 导入数据集
dataset = torchvision.datasets.CIFAR10("../L14/dataset", train=False, transform=torchvision.transforms.ToTensor())
# 做成batch
dataloader = DataLoader(dataset = dataset, batch_size=64)

# 定义模型
class Td(nn.Module):
    def __init__(self):
        super(Td, self).__init__()
        self.relu1 = nn.ReLU()
        self.sigmoid1 = nn.Sigmoid()
        
    def forward(self, input):
        output = self.relu1(input)
        output = self.sigmoid1(output)
        return output

td = Td()
writer = SummaryWriter("./logs_sigmoid")

stp = 0
for data in dataloader:
    imgs, targets = data
    writer.add_images("input", imgs, global_step=stp)
    output = td(imgs)
    writer.add_images("output", output, global_step=stp)
    stp += 1

writer.close()


from torch.utils.data import DataLoader
import torchvision 

dataset = torchvision.datasets.CIFAR10("../L14/dataset", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=64)

for data in dataloader:
    imgs, targets = data
    print(imgs.shape)
    output = torch.reshape(imgs, (1, 1, 1, -1))
    print(output.shape)


from torch.utils.data import DataLoader
import torchvision 
from torch import nn
from torch.nn import Linear
import torch

dataset = torchvision.datasets.CIFAR10("../L14/dataset", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=64, drop_last=True)     # 最后不够做成一个batch_size的直接扔掉不要了


class Model(nn.Module):
    
    def __init__(self):
        super(Model, self).__init__()
        self.linear1 = Linear(196608, 10)    # para1: 原来的size  para2:  希望展成的size
        
    def forward(self, input):
            output = self.linear1(input)
            return output

model = Model()

for data in dataloader:
    imgs, targets = data
    print(imgs.shape)
    output = torch.reshape(imgs, (1, 1, 1, -1))
    print(output.shape)
    output = model(output)
    print(output.shape)


from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential
import torch

class Chenxiaomao(nn.Module):
    
    def __init__(self):
        super(Chenxiaomao, self).__init__()
        self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5,stride=1,padding=2)
        self.maxpool1 = MaxPool2d(kernel_size=2)
        self.conv2 = Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)
        self.maxpool2 = MaxPool2d(kernel_size=2)
        self.conv3 = Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
        self.maxpool3 = MaxPool2d(kernel_size=2)
        self.flatten = Flatten()
        self.linear1 = Linear(1024, 64)
        self.linear2 = Linear(64, 10)
        
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = self.conv3(x)
        x = self.maxpool3(x)
        x = self.flatten(x)
        x = self.linear1(x)
        x = self.linear2(x)        
        return x

chenxiaomao = Chenxiaomao()
print(chenxiaomao)
        
    


input = torch.ones((64, 3, 32, 32))
output = chenxiaomao(input)
print(output.shape)


class Chenxiaomao(nn.Module):
    
    def __init__(self):
        super(Chenxiaomao, self).__init__()
        self.model = Sequential(
            Conv2d(in_channels=3, out_channels=32, kernel_size=5,stride=1,padding=2),
            MaxPool2d(kernel_size=2),
            Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2),
            MaxPool2d(kernel_size=2),
            Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),
            MaxPool2d(kernel_size=2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10),
        )
        
        # self.conv1 = Conv2d(in_channels=3, out_channels=32, kernel_size=5,stride=1,padding=2)
        # self.maxpool1 = MaxPool2d(kernel_size=2)
        # self.conv2 = Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2)
        # self.maxpool2 = MaxPool2d(kernel_size=2)
        # self.conv3 = Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
        # self.maxpool3 = MaxPool2d(kernel_size=2)
        # self.flatten = Flatten()
        # self.linear1 = Linear(1024, 64)
        # self.linear2 = Linear(64, 10)
        
        
    def forward(self, x):
        x = self.model(x)
        return x 
        
        # x = self.conv1(x)
        # x = self.maxpool1(x)
        # x = self.conv2(x)
        # x = self.maxpool2(x)
        # x = self.conv3(x)
        # x = self.maxpool3(x)
        # x = self.flatten(x)
        # x = self.linear1(x)
        # x = self.linear2(x)        
        # return x

chenxiaomao = Chenxiaomao()
print(chenxiaomao)


from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter("../logs_Test_Seq")
writer.add_graph(chenxiaomao, input)



