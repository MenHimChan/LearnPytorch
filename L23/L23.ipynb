{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8259a560-1c80-43a9-ba4c-fe5681fb9b83",
   "metadata": {},
   "source": [
    "# 损失函数与反向传播、优化器\n",
    "---\n",
    "### 1. nn.L1loss\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6c621-109e-40cf-a86f-5b9b8ee77540",
   "metadata": {},
   "source": [
    "\n",
    "class torch.nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "Parameters:\n",
    "+ size_average (bool, optional) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True\n",
    "\n",
    "+ reduce (bool, optional) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True\n",
    "\n",
    " + reduction (str, optional) – Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: 'mean'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d637a045-437d-4cef-9024-9443ad24c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn import L1Loss\n",
    "\n",
    "inputs = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "targets = torch.tensor([1, 2, 5], dtype=torch.float32)\n",
    "\n",
    "inputs  = torch.reshape(inputs, (1, 1, 1, 3))\n",
    "targets = torch.reshape(targets, (1, 1, 1, 3))\n",
    "\n",
    "# 初始化一个实例若不填入任何参数则默认的reduction是'mean'\n",
    "loss = L1Loss()\n",
    "result = loss(inputs, targets)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be2a11-85a3-4fd4-9a62-2a8663feeed8",
   "metadata": {},
   "source": [
    "☝实际上就是对应位置直接相减，求平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfd0deaf-f8db-4f0a-b210-a7f99b909c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "loss = L1Loss(reduction='sum')\n",
    "result = loss(inputs, targets)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03edeb9-7aa9-4435-9517-afbaebfed325",
   "metadata": {},
   "source": [
    "☝实际上就是对应位置直接相减，求总和。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981a950-c86e-44fe-ba68-62b02445b019",
   "metadata": {},
   "source": [
    "### 2. nn.MSELoss\n",
    "---\n",
    "均方差，`mean square error`   \n",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d4c3b80-9e03-454a-ae93-9fa507dc63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3333)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "loss_mse = nn.MSELoss()\n",
    "result_mse = loss_mse(inputs, targets)\n",
    "\n",
    "print(result_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5558a47-603d-4615-98df-400a5fca60a2",
   "metadata": {},
   "source": [
    "### 3. nn.CrossEntropyLoss\n",
    "---\n",
    "+ 处理分类问题\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d2c45a3-03ba-4860-b100-20470b563dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0.1, 0.2, 0.3])\n",
    "y = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92413120-e061-4904-9b1d-ccf3f7588e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.reshape(x, (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d409aea-9904-40a3-a907-72c5d267e820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1019)\n"
     ]
    }
   ],
   "source": [
    "loss_cross = nn.CrossEntropyLoss()\n",
    "result_cross = loss_cross(x, y)\n",
    "print(result_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0eba8e-eca7-4d16-acb2-08b881bae2fb",
   "metadata": {},
   "source": [
    "### 4. .backward() 反向传播, 优化器\n",
    "---\n",
    "+ 计算推理结果和目标之间的差距\n",
    "+ 给反向传播提供了依据   \n",
    "SGD优化器：   \n",
    "https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0891b21b-b2be-48d3-bb29-e9eb69a608bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()\n",
    "        self.model1 = Sequential(\n",
    "        Conv2d(3, 32, 5, padding = 2),\n",
    "        MaxPool2d(2),\n",
    "        Conv2d(32, 32, 5, padding=2),\n",
    "        MaxPool2d(2),\n",
    "        Conv2d(32, 64, 5, padding=2),\n",
    "        MaxPool2d(2),\n",
    "        Flatten(),\n",
    "        Linear(1024, 64),\n",
    "        Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4082df8c-3ba1-46fc-8851-a65c2e757291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\"../dataset\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=1, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "087e0eb5-eee8-4aec-ac26-b3d46ddc2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18804.1738, grad_fn=<AddBackward0>)\n",
      "tensor(16166.6309, grad_fn=<AddBackward0>)\n",
      "tensor(15508.4863, grad_fn=<AddBackward0>)\n",
      "tensor(16208.1094, grad_fn=<AddBackward0>)\n",
      "tensor(17930.9062, grad_fn=<AddBackward0>)\n",
      "tensor(20512.9863, grad_fn=<AddBackward0>)\n",
      "tensor(22462.5352, grad_fn=<AddBackward0>)\n",
      "tensor(23612.9922, grad_fn=<AddBackward0>)\n",
      "tensor(24438.5137, grad_fn=<AddBackward0>)\n",
      "tensor(25003.1914, grad_fn=<AddBackward0>)\n",
      "tensor(25845.9453, grad_fn=<AddBackward0>)\n",
      "tensor(26196.1777, grad_fn=<AddBackward0>)\n",
      "tensor(26821.2383, grad_fn=<AddBackward0>)\n",
      "tensor(27672.5293, grad_fn=<AddBackward0>)\n",
      "tensor(28235.2109, grad_fn=<AddBackward0>)\n",
      "tensor(29414.8438, grad_fn=<AddBackward0>)\n",
      "tensor(32945.1914, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "tudui = Tudui()\n",
    "optim = torch.optim.SGD(tudui.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    # 在原来的数据上进行一轮的学习\n",
    "    for data in dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = tudui(imgs)     # 将imgs图像通过神经网络得到输出\n",
    "        # print(\"Target is\",targets)                       \n",
    "        # print(\"Output is\", outputs)\n",
    "        result_loss = loss(outputs, targets)    # 计算出目标值和真实值之间的交叉熵损失\n",
    "        # print(\"The CrossEntropyLoss is\",result_loss)\n",
    "        optim.zero_grad()              # 上一轮的梯度对本轮训练没有帮助，要清0\n",
    "        result_loss.backward()    #  用当前的result反向传播修改参数\n",
    "        optim.step()\n",
    "        running_loss = running_loss + result_loss\n",
    "        \n",
    "    print(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b5cac-95a2-4c32-aa09-92970f961d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
