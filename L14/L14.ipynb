{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2625af2-bc9d-4ede-b7a9-1caf07e103fe",
   "metadata": {},
   "source": [
    "# torchvisionä¸­çš„æ•°æ®é›†ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcafdbb-a874-4267-9ca6-611b8b0b9bd5",
   "metadata": {},
   "source": [
    "+ torchvision.dataset : å†…ç½®äº†å¸¸ç”¨çš„æ•°æ®é›†(COCO, MNIST, VOCç­‰ç­‰)\n",
    "+ torchvision.models: ä¼šæä¾›å¸¸è§çš„ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”å·²ç»æœ‰é¢„è®­ç»ƒæƒé‡\n",
    "+ torchvision.utils: æä¾›ä¸€äº›å®ç”¨çš„å°å·¥å…·å¦‚Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343b4f6-dae1-45de-b7d7-21cd4c3c1792",
   "metadata": {},
   "source": [
    "### 1. .datasets\n",
    "---\n",
    "```python\n",
    "class CIFAR10(VisionDataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'batches.meta',\n",
    "        'key': 'label_names',\n",
    "        'md5': '5ff9c542aee3614f3951f8cda6e48888',\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        super(CIFAR10, self).__init__(root, transform=transform,\n",
    "                                      target_transform=target_transform)\n",
    "\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        self.data: Any = []\n",
    "        self.targets = []\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        self._load_meta()\n",
    "\n",
    "    def _load_meta(self) -> None:\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
    "        if not check_integrity(path, self.meta['md5']):\n",
    "            raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "        with open(path, 'rb') as infile:\n",
    "            data = pickle.load(infile, encoding='latin1')\n",
    "            self.classes = data[self.meta['key']]\n",
    "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def _check_integrity(self) -> bool:\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45d9f4-7cca-4aa6-bf93-599b873eb5cb",
   "metadata": {},
   "source": [
    "+ root: æœ¬åœ°loadæˆ–è€…æ˜¯ä¸‹è½½ä¹‹åå­˜æ”¾çš„ç›®å½•\n",
    "+ trian: ç”¨äºæŒ‡å®šåœ¨æ•°æ®é›†ä¸‹è½½å®Œæˆåéœ€è¦è½½å…¥å“ªéƒ¨åˆ†æ•°æ®ï¼Œ å¦‚æœè®¾ç½®ä¸º Trueï¼Œåˆ™è¯´æ˜è½½å…¥çš„æ˜¯è¯¥æ•°æ®é›†çš„è®­ç»ƒé›†éƒ¨åˆ†ï¼› å¦‚æœè®¾ç½®ä¸º Falseï¼Œåˆ™è¯´æ˜è½½å…¥çš„æ˜¯è¯¥æ•°æ®é›†çš„æµ‹è¯•é›†éƒ¨åˆ†ï¼›\n",
    "+ download: ç”¨äºæŒ‡å®šæ˜¯å¦ä»ç½‘ç»œä¸Šæ‹‰å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc35800-1037-4d33-93fa-0098fe3abb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root = \"./dataset\", train= True, download = True)\n",
    "test_set = torchvision.datasets.CIFAR10(root = \"./dataset\", train= False, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64caad85-3899-4d6a-b764-39389e637726",
   "metadata": {},
   "source": [
    "ğŸ‘‡**å¯ä»¥çœ‹åˆ°ï¼Œå…¶.classeså±æ€§è¿”å›çš„æ˜¯è¿™ä¸ªæ•°æ®é›†å¯¹è±¡çš„ç±»åˆ«ä¿¡æ¯ï¼Œå¹¶æŠŠæ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªç±»éƒ½æ”¾åœ¨äº†ä¸€ä¸ªåˆ—è¡¨é‡Œé¢ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc8a596-afd1-4de4-a56a-a7bc25a44304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FEEC87964E0>, 6)\n",
      "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FEEC8796390>, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0])\n",
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97a44886-523e-4a15-9af3-0c8dbb60857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(test_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ee7a65-0a89-48c0-a168-0585e237fc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n"
     ]
    }
   ],
   "source": [
    "print(test_set.classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740cfc31-063c-43c7-99f5-ffddb0313ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FEEC73F0BA8>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# å¯ä»¥ç”¨å˜é‡æ¥æ”¶\n",
    "img, target = test_set[0]\n",
    "print(img)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a148b7c2-551a-4f6f-b09d-24ac378c949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bfc7f-0daa-4c8b-88a2-ebf7fb57acc9",
   "metadata": {},
   "source": [
    "### 2.å¯¹æ•°æ®é›†å¯¹è±¡è¿›è¡Œæ‰¹é‡æ“ä½œ\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9324d625-8b33-48e5-9211-9c7b65ab2277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./dataset\", train=True, transform=dataset_transform, download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root=\"./dataset\", train=False, transform=dataset_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814c65e9-4e08-4c2b-b15f-307e2765be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.6196, 0.6235, 0.6471,  ..., 0.5373, 0.4941, 0.4549],\n",
      "         [0.5961, 0.5922, 0.6235,  ..., 0.5333, 0.4902, 0.4667],\n",
      "         [0.5922, 0.5922, 0.6196,  ..., 0.5451, 0.5098, 0.4706],\n",
      "         ...,\n",
      "         [0.2667, 0.1647, 0.1216,  ..., 0.1490, 0.0510, 0.1569],\n",
      "         [0.2392, 0.1922, 0.1373,  ..., 0.1020, 0.1137, 0.0784],\n",
      "         [0.2118, 0.2196, 0.1765,  ..., 0.0941, 0.1333, 0.0824]],\n",
      "\n",
      "        [[0.4392, 0.4353, 0.4549,  ..., 0.3725, 0.3569, 0.3333],\n",
      "         [0.4392, 0.4314, 0.4471,  ..., 0.3725, 0.3569, 0.3451],\n",
      "         [0.4314, 0.4275, 0.4353,  ..., 0.3843, 0.3725, 0.3490],\n",
      "         ...,\n",
      "         [0.4863, 0.3922, 0.3451,  ..., 0.3804, 0.2510, 0.3333],\n",
      "         [0.4549, 0.4000, 0.3333,  ..., 0.3216, 0.3216, 0.2510],\n",
      "         [0.4196, 0.4118, 0.3490,  ..., 0.3020, 0.3294, 0.2627]],\n",
      "\n",
      "        [[0.1922, 0.1843, 0.2000,  ..., 0.1412, 0.1412, 0.1294],\n",
      "         [0.2000, 0.1569, 0.1765,  ..., 0.1216, 0.1255, 0.1333],\n",
      "         [0.1843, 0.1294, 0.1412,  ..., 0.1333, 0.1333, 0.1294],\n",
      "         ...,\n",
      "         [0.6941, 0.5804, 0.5373,  ..., 0.5725, 0.4235, 0.4980],\n",
      "         [0.6588, 0.5804, 0.5176,  ..., 0.5098, 0.4941, 0.4196],\n",
      "         [0.6275, 0.5843, 0.5176,  ..., 0.4863, 0.5059, 0.4314]]]), 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17cca0a9-5946-4675-a568-db56a0c05ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "for i in range(10):                                           # å†™å…¥10å¼ å›¾ç‰‡è¿›å…¥Tensorboard\n",
    "    img, target = test_set[i]\n",
    "    writer.add_image(\"Test_Set\", img, i)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35832368-c98c-431b-af55-21c1b67c40f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
